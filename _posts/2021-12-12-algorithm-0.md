---
date: 2021-12-12
title: "알고리즘 정리 1"

excerpt: "Dynamic Programming"

categories: 
  - algorithm
tags: 
  - study
  - algorithm

# 목차
toc: true  
toc_sticky: true 
---

## Chapter 6. Dynamic Programming

---
          
## 1. Algorithmic Paradigms
  - Greedy : Build up a solution incrementally, myopically optimizing some local criterion <br> ex) MST
  - Divide-and-conquer : **Break up** a problem into sub-problems, solve each sub-problem independently, and **combine** solution to sub-problems to form solution to original problem <br> ex) Merge sort
  - Dynamic programming : Break up a problem into a series of overlapping sub-problems, and build up solutions to larger and larger sub-problems. <br> -> recursion
    - famous dynamic programming algorithms.
      - Unix diff for comparing two files
      - Viterbi for hidden Markov models
      - Smith-Waterman for genetic sequence alighment
      - **Bellman-Ford for shortest path routing in networks**
      - Cocke-Kasami-Younger for parsing context free grammars.

## 2. Weighted Interval Scheduling
- Definition
  - Job j starts at `s(j)`, finishes at `f(j)`, and has weight or value `v(j)`.
  - Two jobs **compatible** if they don't overlap.
  - Goal : find **max weight subset** of mutually compatible jobs
- Unweighted Interval Scheduling Review
  - **Greedy algorithm** works if all weights are 1. -> consider jobs in ascending order of **finish time**.
  - Observation : Greedy algorithm can fail spectacularly if arbitrary weights are allowed.

<p align='center'><img src='https://github.com/brainini/brainini.github.io/blob/main/assets/img/DP1.jpg?raw=1' width = '800' ></p>

- Notation : Label jobs by finishing time : $f_1\leq f_2 \leq ... \leq f_n$ <br>
  p(j) = largest index $i < j$ such that job i is compatible with j.
  <br> Ex : p(8) = 5, p(7) = 3, p(2) = 0.
  <p align='center'><img src='https://github.com/brainini/brainini.github.io/blob/main/assets/img/DP2.jpg?raw=1' width = '800' ></p>

### Dynamic Programming : Binary Choice
- OPT(j) = value of optimal solution to the problem consisting of job requests 1, 2, .., j.
- Case1 : OPT selects job j.
  - collect **profit** $v_j$
  - can't use incompatible jobs {p(j) + 1, p(j) + 2, ..., j-1}
  - must include optimal solutio nto problem consisting of remaining compatible jobs 1~p(j)
- Case2 : OPT does not select job j.
  - optimal solution to remaining compatible jobs 1, 2, .., j-1

$$OPT(j)=\begin{cases}0,\;if\;j=0\\max(v_j+OPT(p(j)), OPT(j-1)),\;otherwise\end{cases}$$

### Brute force algorithm
```python
Input: n, s1, .., sn, f1, .., fn, v1, ..., vn
Sort jobs by finish times # O(nlog2n)
Compute p(1), p(2), ... ,p(n) # O(nlogn)

Compute-Opt(j) {
  if(j = 0)
    return 0
  else
    return max(vj + Compute-Opt(p(j)), Compute-Opt(j-1))
}
```

- Observation : Recursive algorithm fails because of redundant sub-problems -> exponential algorithms. <br> 이러한 redundant 문제를 memoization으로 극복!!!

### Memoization
Store results of each sub-problem in a cache;

```python
Input: n, s1, .., sn, f1, .., fn, v1, ..., vn
Sort jobs by finish times # O(nlog2n)
Compute p(1), p(2), ... ,p(n) # start time Sort-> O(n)+O(nlogn) = O(nlogn)

for j = 1 to n
  M[j] = empty # global array
M[0] = 0

M-Compute-Opt(j) {
  if(M[j] is empty)
    M[j] = max(vj + M-Compute-Opt(p(j)), M-Compute-Opt(j-1))
  return M[j]
}
```
- Running Time : $O(nlogn)$
  - $O(n)$ if jobs are pre-sorted by start and finish times.

## 3. Segmented Least Squares
- Least Squares
  - Given n points in the plane: $(x_1, y_1), (x_2, y_2), .., (x_n, y_n)$.
  - Find a line y = ax + b that minimizes the sum of the suqred error

$$SSE = \displaystyle\sum_{i=1}^{n}{(y_i-ax_i-b)^2}$$

- Segmented least squares : find a sequence of lines that minimizes
  - the sum of the sums of the squared errors E in each segment
  - the number of lines L 

    Tradeoff function : $E + cL$ for some constant c > 0  

<p align='center'><img src='https://github.com/brainini/brainini.github.io/blob/main/assets/img/DP3.jpg?raw=1' width = '500' ></p>

### Multiway Choice
- Notation
  - OPT(j) = minimum cost(E+cL) for points $p_1, p_{i+1}, ..., p_j$
  - e(i, j) = minimum sum of squares for points $p_i, p_{i+1}, ..., p_j$

$$OPT(j)=\begin{cases}0,\;if\;j=0\\\displaystyle\min_{1\leq i\leq j}(e(i, j)+c+OPT(i-1))),\;otherwise\end{cases}$$

- Algorithm

```python
Input : n, P1,...,Pn, c

Segmented-Least-Squares() {
  M[0] = 0
  for j = 1 to n
    for i = 1 to j # O(n^2)
      compute the least square error e_ij for the segment pi, ..., pj # O(n)
  
  for j = 1 to n
    M[j] = min(i = 1 to j)(e_ij + c + M[i-1])

  return M[n]
}
```

- Running time : $O(n^3)$

## 4. Knapsack Problem
- Def
  - Given n objects and a "knapsack".
  - Item i weighs $w_i > 0$ kilograms and has value $v_i > 0$.
  - Knapsack has capacity of W kilograms.
  - Goal : fill knapsack so as to maximize total value.
- Greedy : repeatedly add item with maximum ratio $v_i / w_i$
  - not optimal!

### False Start
- Def : OPT(i) = max profit subset of items 1, ..., i
  - Case 1 : OPT does not select item i
    - OPT selects best of {1, 2, ..., i-1}
  - Case 2 : OPT selects item i
    - we don't know if we have enough room for i

  - Need more sub-problems!!

### Adding a New Variable
- Def : OPT(i, w) = max profit subset of items 1,..,i **with weight limit w.**
  - Case 1 : OPT does not select item i
    - OPT(i-1, w)
  - Case 2 : OPT selects item i
    - OPT(i-1, w-wi) + vi

$$OPT(i, w)=\begin{cases}0,\;if\;i=0\\OPT(i-1, w),\;if\;w_i>w\\max(OPT(i-1, w), v_i+OPT(i-1, w-w_i)),\;otherwise\end{cases}$$

- Fill up an n-by-W array -> pseudo polynomial

```python
Input : n, W, w1,...,wn, v1, ..., vn

for w = 0 to W
  M[0, w] = 0

for i = 1 to n
  for w = 1 to W
    if (wi > w)
      M[i, w] = M[i-1, w]
    else
      M[i, w] = max{M[i-1, w], vi + M[i-1, w-wi]}

  return M[n, W]
}
```
- Running time = $O(nW)$
  - Not polynomial in input size!
  - **Pseudo-polynomial**
  - Decision version of Knapsack is NP-complete

## 5. Shortest Paths
- Failed Attempts
  - Dijkstra : Can fail if negative edge costs.
  - Re-weighting : Adding a constant to every edge weight can fail
- Negative cost cycle.
<p align='center'><img src='https://github.com/brainini/brainini.github.io/blob/main/assets/img/DP4.jpg?raw=1' width = '300' ></p>

- Observation : If some path from s to t contains a negative cost cycle, there does not exist a shortest s-t path; otherwise , **there exists one that is simple**.

<p align='center'><img src='https://github.com/brainini/brainini.github.io/blob/main/assets/img/DP5.jpg?raw=1' width = '300' ></p>

- Def : OPT(i, v) = length of shortest v-t path P using at most i edges.
  - Case 1 : P uses at most i-1 edges.
    - OPT(i, v) = OPT(i-1, v)
  - Case 2 : P uses exactly i edges.
    - if (v, w) is first edge, then OPT uses (v, w), and then selects best w-t path using at most i-1 edges

$$OPT(i, v)=\begin{cases}0,\;if\;i=0\\min[OPT(i-1, v), \displaystyle\min_{(v, w)\in E}(OPT(i-1, w)+c_{vw}))],\;otherwise\end{cases}$$

- Remark : if no negative cycles, then OPT(n-1, v) = length of shortest v-t path.
  
```python
Shortest-Path(G, t) {
  foreach node v in V
    M[0, v] = inf
  M[0, t] = 0

  for i = 1 to n-1
    foreach node v in V
      M[i, v] = M[i-1, v]
    foreach edge(v, w) in E
      M[i, v] = min{M[i, v], M[i-1, w] + c_vw}
}
```

- Analysis : $\theta(mn)$ time, $\theta(n^2)$ space.
- Practical Improvements
  - only one array M[v] = shortest v-t path 
  - No need to check edges (v, w) unless M[w] changed in previous iteration

- Bellman-Ford : Efficient Implementation

```python
Push-Based-Shortest-Path(G, s, t) {
  foreach node v in V{
    M[v] = inf
    successor[v] = 0
  }

  M[t] = 0
  for i = 1 to n-1 {
    foreach node w in V {
    if (M[w] has been updated in previous iteration){
        foreach node v such that (v, w) in E {
          if (M[v] > M[w] + c_vw) {
            M[v] = M[w] + c_vw
            successor[v] = w
          }
        }
    } If no M[w] value changed in iteration i, stop. # fast
  }
}
```

## 6. Negative Cycles in a Graph
- Lemma : If OPT(n, v) = OPT(n-1, v) for all v, then no negative cycles.
  - Pf : Bellman-Ford algorithm
- Lemma : If OPT(n, v) < OPT(n-1, v) for some node v, then shortest path from v to t contains a **cycle W**. More over W has **negative cost**.
  - Pf : OPT(n, v) < OPT(n-1, v), OPT(n, v)의 path P는 n개의 edge를 가진다. 비둘기집 원리에 의해 P는 directed cycle W를 포함한다. 이 W를 제거해서 만들어진 v-t path를 P'라 하자. 그러면 $OPT(n-1, v)\leq c(P')$ 가 성립한다. <br>
  결국, $OPT(v, n) = C(P)=C(P')+C(W) < OPT(n-1, v)\leq c(P')$

- Theorem : Can detect negative cost cycle in O(mn) time.
  - Add new node t and connect all nodes to t with 0-cost edge.
  - Check if OPT(n, v) = OPT(n-1, v) for all nodes v.
    - if yes, no negative cycles
    - if no, then extract cycle from shortest path from v to t
